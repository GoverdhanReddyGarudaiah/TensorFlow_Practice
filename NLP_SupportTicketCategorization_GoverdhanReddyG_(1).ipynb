{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GoverdhanReddyGarudaiah/TensorFlow_Practice/blob/main/NLP_SupportTicketCategorization_GoverdhanReddyG_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny8YqLruKipO"
      },
      "source": [
        "## Installing and Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L-kBLkSNKd1N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Ignore Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYoQIRLWJsJs"
      },
      "source": [
        "## Data Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4KJ_sxjJeKj",
        "outputId": "2d982ff2-7271-43ff-bb63-4144cc18cab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4gICqRPKzbm"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/AIML/Support_ticket_text_data_mid_term.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COyxw_B9KT6A"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0g20BUE8ZDp"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL_c8EiZ8Z3-"
      },
      "source": [
        "\n",
        "\n",
        "1.   There are two features in the data set 1. Support Ticket ID 2. Support Ticket Text\n",
        "2.   There are no null values in any of the features\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKuArwKvJxC7"
      },
      "source": [
        "## Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nESrWMtW7b2u"
      },
      "outputs": [],
      "source": [
        "#Installation for GPU llama-cpp-python\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgltVNMi8BF9"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM_NExMWKOzn"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n",
        "model_basename = \"llama-2-13b-chat.Q5_K_M.gguf\"\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=model_name_or_path,\n",
        "    filename=model_basename\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQts23Q3Kn1s"
      },
      "outputs": [],
      "source": [
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=2,\n",
        "    n_batch=512,\n",
        "    n_gpu_layers=43,\n",
        "    n_ctx=4096,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGEIPxYQauG4"
      },
      "source": [
        "This function would accept Support ticket as one input parameter and System Message to specify the task as second paramter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DV48u9NYLWbl"
      },
      "outputs": [],
      "source": [
        "def generateLLAMAPrompt(SupportText, SystemMessage, MaxTokens, Temp):\n",
        "  system_message = f\"\"\"[INST]<<SYS>>{SystemMessage}\"<</SYS>>[/INST]\"\"\"\n",
        "  prompt = f\"{SupportText}\\n{system_message}\"\n",
        "  response = lcpp_llm(\n",
        "        prompt=prompt,\n",
        "        max_tokens=MaxTokens,\n",
        "        temperature=Temp,\n",
        "        top_p=0.15,\n",
        "        repeat_penalty=1.2,\n",
        "        top_k=50,\n",
        "        stop=['INST'],\n",
        "        echo=False\n",
        "    )\n",
        "  response_text = response[\"choices\"][0][\"text\"]\n",
        "  return response_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GqSE1qwJz9Q"
      },
      "source": [
        "## Task 1 - Ticket Categorization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QueryQuestionTicketCategorization = \"Based on the information provided, the category of this support ticket is: .Return category only\""
      ],
      "metadata": {
        "id": "9NMJ806VCZgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-gxJPvVmFm9"
      },
      "outputs": [],
      "source": [
        "def getTicketCategoryFromModelResponse(CurrentText):\n",
        "    LLAMA_Response = generateLLAMAPrompt(CurrentText, QueryQuestionTicketCategorization)\n",
        "    colon_index = LLAMA_Response.find(':')\n",
        "    if colon_index != -1:\n",
        "        category = LLAMA_Response[colon_index+1:].strip()\n",
        "        pattern = r'[*\":.]'\n",
        "        category = re.sub(pattern, '', category)\n",
        "        return category.replace('Category','')\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['ticket_category'] = df['support_ticket_text'].apply(lambda x: getTicketCategoryFromModelResponse(x))"
      ],
      "metadata": {
        "id": "xhR-smVNNBeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ticket_category']"
      ],
      "metadata": {
        "id": "aal03qR4NWeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbgMXAkpJ3-d"
      },
      "source": [
        "## Task 2 - Creating Tags"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QueryQuestionCreateTags = \"Based on the information provided, what are the tags for this support ticket: .Return tags only\""
      ],
      "metadata": {
        "id": "yF7dxkuLfaVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getTicketTagsFromModelResponse(CurrentText):\n",
        "    LLAMA_Response = generateLLAMAPrompt(CurrentText, QueryQuestionCreateTags, 100, 0.01)\n",
        "    print(LLAMA_Response)\n",
        "    colon_index = LLAMA_Response.find(':')\n",
        "    if colon_index != -1:\n",
        "        category = LLAMA_Response[colon_index+1:].strip()\n",
        "        pattern = r'[*\":.]'\n",
        "        category = re.sub(pattern, '', category)\n",
        "        return category.replace('Category','')\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "EMH20Hl7fgYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qry = \"I've accidentally deleted essential work documents, causing substantial data loss. I understand the need to avoid further actions on my device. Can you please prioritize the data recovery process and guide me through it?\""
      ],
      "metadata": {
        "id": "XnkS3r7lgP4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getTicketTagsFromModelResponse(qry)"
      ],
      "metadata": {
        "id": "BtaQI91ggRuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getTicketTagsFromModelResponse(\"Urgent help required! My laptop refuses to start, and I have a crucial presentation scheduled for tomorrow. I've attempted a restart, but it hasn't worked. Please provide immediate assistance to resolve this hardware issue\")"
      ],
      "metadata": {
        "id": "GBK7Qqzof0It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k29O6h4YJ47t"
      },
      "source": [
        "## Task 3 - Assigning Priority and ETA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QueryQuestionAssignPriority = \"Based on the information provided, what would be the urgency of the support ticket? Return priortity as Immediate, High, Medium, Low. Return as Priority: \""
      ],
      "metadata": {
        "id": "hjsStps9gpKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getTicketCategoryFromModelResponse(CurrentText):\n",
        "    LLAMA_Response = generateLLAMAPrompt(CurrentText, QueryQuestionAssignPriority, 30, 0.001)\n",
        "    print(LLAMA_Response)\n",
        "    colon_index = LLAMA_Response.find(':')\n",
        "    if colon_index != -1:\n",
        "        category = LLAMA_Response[colon_index+1:].strip()\n",
        "        pattern = r'[*\":.]'\n",
        "        category = re.sub(pattern, '', category)\n",
        "        return category.replace('Category','')\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "EXUe0w0EhJTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(getTicketCategoryFromModelResponse(qry))"
      ],
      "metadata": {
        "id": "q2J4O42FhFpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMA9loW0J7Kw"
      },
      "source": [
        "## Task 4 - Creating a Draft Response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QueryQuestionDraftResponse = \"Based on the information provided, respond back to customer along with estimated time for response from support team\""
      ],
      "metadata": {
        "id": "MabpH4ePnZWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSD-26wwJ-LR"
      },
      "source": [
        "## Model Output Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dRCzU5WKAap"
      },
      "source": [
        "## Insights and Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnFsYWnIJ1z3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}